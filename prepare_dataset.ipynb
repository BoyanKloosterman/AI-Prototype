{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26031b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA CLEANING PROCESS\n",
      "============================================================\n",
      "Origineel: 211 rijen, 20 kolommen\n",
      "\n",
      "1. Kleur-kolommen verwijderd: ['Rood', 'Groen', 'Blauw', 'Geel']\n",
      "   -> 16 kolommen resterend\n",
      "\n",
      "2. shortdescription aangevuld met description (eerste 200 chars)\n",
      "   Voor: 20 NULL, Na: 0 NULL\n",
      "\n",
      "3. learningoutcomes aangevuld met 'Nog niet bepaald'\n",
      "   Voor: 5 NULL, Na: 0 NULL\n",
      "\n",
      "4. start_date geconverteerd naar datetime\n",
      "   Ongeldige datums naar NaT: 0\n",
      "\n",
      "5. Duplicaten op 'id'\n",
      "   Gevonden: 0, Rijen voor: 211, na: 211\n",
      "\n",
      "6. Tekstvelden normaliseren en lemmatiseren\n",
      "   - Verwerken: shortdescription -> shortdescription_clean\n",
      "   - Verwerken: description -> description_clean\n",
      "   - Verwerken: content -> content_clean\n",
      "   - Verwerken: learningoutcomes -> learningoutcomes_clean\n",
      "\n",
      "============================================================\n",
      "FINALE DATASET STATUS\n",
      "============================================================\n",
      "Rijen: 211\n",
      "Kolommen: 20\n",
      "Totaal NULL waarden: 0\n",
      "\n",
      "NULL waarden per kolom (alleen > 0):\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Sample (eerste 3 rijen):\n",
      "    id                          name  \\\n",
      "0  159  Kennismaking met Psychologie   \n",
      "1  160   Learning and working abroad   \n",
      "2  161       Proactieve zorgplanning   \n",
      "\n",
      "                                    shortdescription  \\\n",
      "0  Brein, gedragsbeinvloeding, ontwikkelingspsych...   \n",
      "1  Internationaal, persoonlijke ontwikkeling, ver...   \n",
      "2     Proactieve zorgplanning, cocreatie, ziekenhuis   \n",
      "\n",
      "                              shortdescription_clean  \\\n",
      "0  brein gedragsbeinvloeding ontwikkelingspsychol...   \n",
      "1  internationaal persoonlijke ontwikkeling verpl...   \n",
      "2       proactieve zorgplanning cocreatie ziekenhuis   \n",
      "\n",
      "                                    learningoutcomes  \\\n",
      "0  A. Je beantwoordt vragen in een meerkeuze kenn...   \n",
      "1  De student toont professioneel gedrag conform ...   \n",
      "2  De student past pro actieve zorgplanning toe b...   \n",
      "\n",
      "                              learningoutcomes_clean  \n",
      "0  beantwoordt vragen meerkeuze kennistoets waari...  \n",
      "1  student toont professioneel gedrag conform ber...  \n",
      "2  student past pro actieve zorgplanning toe binn...  \n",
      "\n",
      "OPGESLAGEN: Uitgebreide_VKM_dataset_cleaned.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kloos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kloos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kloos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\kloos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "INPUT_FILE = \"Uitgebreide_VKM_dataset.csv\"\n",
    "OUTPUT_FILE = \"Uitgebreide_VKM_dataset_cleaned.csv\"\n",
    "\n",
    "# Kolommen die we als tekst willen schoonmaken\n",
    "TEXT_COLS = [\n",
    "    \"shortdescription\",\n",
    "    \"description\",\n",
    "    \"content\",\n",
    "    \"learningoutcomes\"\n",
    "]\n",
    "\n",
    "# Stopwoorden en lemmatizer\n",
    "# Kies 'english' of 'dutch' afhankelijk van je dataset\n",
    "STOP_LANG = \"dutch\"   # of \"english\"\n",
    "stop_words = set(stopwords.words(STOP_LANG))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def normalize_length(tokens, max_len=200):\n",
    "    \"\"\"Beperk tokens tot een vaste maximale lengte om scheefheid te verminderen.\"\"\"\n",
    "    return tokens[:max_len]\n",
    "\n",
    "\n",
    "def normalize_text(text: str) -> str:\n",
    "    \"\"\"Maak tekst schoon, lemmatiseer en normaliseer lengte.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "\n",
    "    text = str(text).lower()\n",
    "\n",
    "    # Verwijder alles behalve letters, cijfers en spaties\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\sáéíóúàèìòùäëïöüâêîôûçñ]\", \" \", text)\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Filter op stopwoorden en korte tokens\n",
    "    tokens = [t for t in tokens if t not in stop_words and len(t) > 2]\n",
    "\n",
    "    # Lemmatiseer\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "\n",
    "    tokens = normalize_length(tokens, max_len=200)\n",
    "\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "\n",
    "def clean_vkm_dataset(input_file: str, output_file: str) -> pd.DataFrame:\n",
    "    # Data inladen\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"DATA CLEANING PROCESS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Origineel: {df.shape[0]} rijen, {df.shape[1]} kolommen\")\n",
    "\n",
    "    df_cleaned = df.copy()\n",
    "\n",
    "    # 1. Verwijder de kleur-kolommen (Rood, Groen, Blauw, Geel) als ze bestaan\n",
    "    kleur_kolommen = [\"Rood\", \"Groen\", \"Blauw\", \"Geel\"]\n",
    "    bestaande_kleuren = [c for c in kleur_kolommen if c in df_cleaned.columns]\n",
    "    if bestaande_kleuren:\n",
    "        df_cleaned = df_cleaned.drop(columns=bestaande_kleuren)\n",
    "        print(f\"\\n1. Kleur-kolommen verwijderd: {bestaande_kleuren}\")\n",
    "    else:\n",
    "        print(\"\\n1. Geen kleur-kolommen gevonden om te verwijderen\")\n",
    "\n",
    "    print(f\"   -> {df_cleaned.shape[1]} kolommen resterend\")\n",
    "\n",
    "    # 2. Vul lege waarden in shortdescription met eerste 200 chars van description\n",
    "    if \"shortdescription\" in df_cleaned.columns and \"description\" in df_cleaned.columns:\n",
    "        before_nulls = df_cleaned[\"shortdescription\"].isna().sum()\n",
    "        df_cleaned[\"shortdescription\"] = df_cleaned[\"shortdescription\"].fillna(\n",
    "            df_cleaned[\"description\"].astype(str).str[:200]\n",
    "        )\n",
    "        after_nulls = df_cleaned[\"shortdescription\"].isna().sum()\n",
    "        print(f\"\\n2. shortdescription aangevuld met description (eerste 200 chars)\")\n",
    "        print(f\"   Voor: {before_nulls} NULL, Na: {after_nulls} NULL\")\n",
    "    else:\n",
    "        print(\"\\n2. Kolommen shortdescription of description ontbreken, stap overgeslagen\")\n",
    "\n",
    "    # 3. Vul lege waarden in learningoutcomes\n",
    "    if \"learningoutcomes\" in df_cleaned.columns:\n",
    "        before_nulls = df_cleaned[\"learningoutcomes\"].isna().sum()\n",
    "        df_cleaned[\"learningoutcomes\"] = df_cleaned[\"learningoutcomes\"].fillna(\"Nog niet bepaald\")\n",
    "        after_nulls = df_cleaned[\"learningoutcomes\"].isna().sum()\n",
    "        print(f\"\\n3. learningoutcomes aangevuld met 'Nog niet bepaald'\")\n",
    "        print(f\"   Voor: {before_nulls} NULL, Na: {after_nulls} NULL\")\n",
    "    else:\n",
    "        print(\"\\n3. Kolom learningoutcomes ontbreekt, stap overgeslagen\")\n",
    "\n",
    "    # 4. start_date naar geldige datetime\n",
    "    if \"start_date\" in df_cleaned.columns:\n",
    "        df_cleaned[\"start_date\"] = pd.to_datetime(df_cleaned[\"start_date\"], errors=\"coerce\")\n",
    "        invalid_dates = df_cleaned[\"start_date\"].isna().sum()\n",
    "        print(f\"\\n4. start_date geconverteerd naar datetime\")\n",
    "        print(f\"   Ongeldige datums naar NaT: {invalid_dates}\")\n",
    "    else:\n",
    "        print(\"\\n4. Kolom start_date ontbreekt, stap overgeslagen\")\n",
    "\n",
    "    # 5. Duplicaten op id droppen\n",
    "    if \"id\" in df_cleaned.columns:\n",
    "        before = df_cleaned.shape[0]\n",
    "        duplicates = df_cleaned.duplicated(subset=[\"id\"]).sum()\n",
    "        df_cleaned = df_cleaned.drop_duplicates(subset=[\"id\"])\n",
    "        after = df_cleaned.shape[0]\n",
    "        print(f\"\\n5. Duplicaten op 'id'\")\n",
    "        print(f\"   Gevonden: {duplicates}, Rijen voor: {before}, na: {after}\")\n",
    "    else:\n",
    "        print(\"\\n5. Kolom 'id' ontbreekt, duplicaten-check overgeslagen\")\n",
    "\n",
    "    # 6. Tekstvelden schoonmaken + lemmatizeren\n",
    "    print(\"\\n6. Tekstvelden normaliseren en lemmatiseren\")\n",
    "    for col in TEXT_COLS:\n",
    "        if col in df_cleaned.columns:\n",
    "            clean_col = f\"{col}_clean\"\n",
    "            print(f\"   - Verwerken: {col} -> {clean_col}\")\n",
    "            df_cleaned[clean_col] = df_cleaned[col].apply(normalize_text)\n",
    "        else:\n",
    "            print(f\"   - Kolom {col} niet gevonden, overgeslagen\")\n",
    "\n",
    "    # 7. Globale missing value check\n",
    "    total_nulls = df_cleaned.isnull().sum().sum()\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"FINALE DATASET STATUS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Rijen: {df_cleaned.shape[0]}\")\n",
    "    print(f\"Kolommen: {df_cleaned.shape[1]}\")\n",
    "    print(f\"Totaal NULL waarden: {total_nulls}\")\n",
    "\n",
    "    # Optioneel: per kolom\n",
    "    print(\"\\nNULL waarden per kolom (alleen > 0):\")\n",
    "    nulls_per_col = df_cleaned.isnull().sum()\n",
    "    print(nulls_per_col[nulls_per_col > 0])\n",
    "\n",
    "    # Sample tonen\n",
    "    sample_cols = [c for c in [\"id\", \"name\", \"shortdescription\", \"shortdescription_clean\", \"learningoutcomes\", \"learningoutcomes_clean\"] if c in df_cleaned.columns]\n",
    "    print(\"\\nSample (eerste 3 rijen):\")\n",
    "    print(df_cleaned[sample_cols].head(3))\n",
    "\n",
    "    # Opslaan\n",
    "    df_cleaned.to_csv(output_file, index=False)\n",
    "    print(f\"\\nOPGESLAGEN: {output_file}\")\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_cleaned = clean_vkm_dataset(INPUT_FILE, OUTPUT_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b924c2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned[\"fulltext_clean\"] = (\n",
    "    df_cleaned.get(\"name_clean\", \"\") + \" \" +\n",
    "    df_cleaned.get(\"shortdescription_clean\", \"\") + \" \" +\n",
    "    df_cleaned.get(\"description_clean\", \"\") + \" \" +\n",
    "    df_cleaned.get(\"content_clean\", \"\") + \" \" +\n",
    "    df_cleaned.get(\"learningoutcomes_clean\", \"\")\n",
    ").str.strip()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
